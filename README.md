# Microservices ECS Fargate Project

## Overview
This project provides a complete, automated deployment of a system with two Docker-based microservices using Amazon ECS with Fargate. It includes:

- Elastic Load Balancer (ALB)
- Amazon S3 Bucket
- Amazon SQS Queue
- AWS Systems Manager Parameter Store
- GitHub Actions CI/CD pipeline
- Infrastructure managed via Terraform

## Architecture Summary
- **ECS Fargate Cluster** ‚Äì Serverless hosting for microservices
- **Microservice 1** ‚Äì REST API behind an ALB that validates a token and sends data to SQS
- **Microservice 2** ‚Äì Consumes messages from SQS and writes them to S3
- **S3** ‚Äì Stores data from Microservice 2
- **SQS** ‚Äì Acts as a queue between the services
- **SSM Parameter Store** ‚Äì Securely stores the token
- **IAM Roles** ‚Äì Provides least-privilege access between services
- **GitHub Actions** ‚Äì Automates build, push, and deploy steps

## Prerequisites

### Local Requirements
- Terraform
- AWS CLI
- Git
- Docker

### GitHub Setup
- GitHub account with a public repository
- AWS credentials (access key and secret key)

## GitHub Secrets Configuration

### 1. Set Up AWS Credentials
In AWS Console:
1. Go to IAM ‚Üí Users ‚Üí Create or select a user
2. Attach the `AdministratorAccess` policy (or scoped one)
3. Generate access keys

In GitHub:
1. Go to your repo ‚Üí Settings ‚Üí Secrets and variables ‚Üí Actions ‚Üí New repository secret
2. Add the following secrets:
   - `AWS_ACCESS_KEY_ID`
   - `AWS_SECRET_ACCESS_KEY`
   - `MICROSERVICE_TOKEN` ‚Äì Custom token for API validation

### 2. Terraform Backend Configuration
1. Create an S3 bucket for the Terraform state
2. (Optional) Create a DynamoDB table for state locking
3. Edit the `backend` block in `main.tf` to include the S3 bucket name and key

Example policy for S3 bucket access:
```json
"Action": [
  "s3:GetObject",
  "s3:PutObject",
  "s3:DeleteObject",
  "s3:ListBucket"
]
```

### 3. Create ECR Repositories
In AWS ECR Console, create two repositories:
- `microservice1`
- `microservice2`

These will store the container images for both services.

## Microservices Description

### Microservice 1 (API Service)
- Listens for HTTP POST requests via ALB
- Validates a token from AWS SSM
- Checks timestamp format
- Publishes the payload to SQS

### Microservice 2 (Worker Service)
- Periodically pulls messages from SQS
- Stores the parsed payload in S3 with a structured path

## CI/CD Pipeline
GitHub Actions is used for CI/CD.

### Workflows
- **Deploy Microservice1** ‚Äì Builds and pushes the first microservice image to ECR
- **Deploy Microservice2** ‚Äì Builds and pushes the second microservice image to ECR
- **Terraform CI/CD** ‚Äì
  - `terraform-apply`: Provisions the infrastructure
  - Leave empty for `terraform plan` (dry run)
  - `terraform-destroy`: Destroys all infrastructure

You can trigger these workflows manually from the **Actions** tab in GitHub.

## Terraform Infrastructure
The following resources are provisioned by Terraform:

### ‚úÖ Amazon ECS (Elastic Container Service)
- Clusters
- Task Definitions for both microservices
- ECS Services for both microservices

### ‚úÖ Amazon ECR
- `microservice1` and `microservice2` repositories (as data sources)

### ‚úÖ Amazon SQS
- Queue for microservice communication
- IAM policy attachments for SQS access

### ‚úÖ Amazon S3
- S3 bucket to store Microservice 2 output

### ‚úÖ AWS IAM
- Execution roles for ECS tasks
- Role policies for accessing S3, SQS, and SSM

### ‚úÖ AWS SSM Parameter Store
- Secure token storage for Microservice 1

### ‚úÖ Amazon VPC
- VPC with subnets and routing

### ‚úÖ Elastic Load Balancer (ALB)
- ALB for exposing Microservice 1
- Target groups for ECS tasks

### ‚úÖ Security Groups
- ALB and ECS task security groups

### ‚úÖ Terraform Data Sources
- `aws_caller_identity`
- `aws_ecr_repository.service1`
- `aws_ecr_repository.service2`

## Configuration Files

### `test.tfvars`
- Region selection
- Global tags and shared variables

### `local.tf`
- Infrastructure configs like names, CPU, memory, etc.

> ‚ö†Ô∏è Do not modify any code inside the `module` folders.

## Security Considerations
- AWS credentials and tokens are securely stored in GitHub Secrets and SSM
- IAM roles follow least-privilege principle
- Public subnets are used for demonstration only ‚Äî for production, move sensitive components (like Microservice 2) to private subnets

## Verification & Testing
Once deployed:
- Test Microservice 1 via the ALB endpoint: `https://your-alb-dns-name/api`
- Send a POST request with token and payload
- Verify that Microservice 2 writes the message to the S3 bucket

### üî¨ Example Test Request

Once the infrastructure is up and running, you can test Microservice 1 with the following `curl` command:

```bash
curl -X POST http://<ALB-DNS>/process \
  -H "Content-Type: application/json" \
  -H "Authorization: supersecrettoken123" \
  -d '{"email_timestream": "user@example.com_2025-04-17T12:00:00Z"}'
‚úÖ Replace <ALB-DNS> with the actual DNS name of your Application Load Balancer.

‚úÖ Replace the token with the one stored in your MICROSERVICE_TOKEN secret (if different).
---

